import os
import re
import time
import requests
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys

# ìˆ˜ì • : ì§€ì—­ í•¨ìˆ˜ > ì „ì—­ í•¨ìˆ˜ë¡œ ë³€ê²½ 
# main.pyì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•¨
BASE_URL = "https://apply.lh.or.kr"
LIST_URL = BASE_URL + "/lhapply/apply/wt/wrtanc/selectWrtancList.do?viewType=srch"
DOWNLOAD_URL = BASE_URL + "/lhapply/lhFile.do"
DOWNLOAD_DIR = "./downloads"
HEADERS = {"User-Agent": "Mozilla/5.0"}
DRIVER_PATH = os.path.join(os.getcwd(), "chromedriver.exe")
    

def collect_lh_file_urls():
    # (1) ë‹¤ìš´ë¡œë“œ í´ë” & ì´ë¯¸ ë°›ì€ íŒŒì¼ ëª©ë¡ ì¤€ë¹„
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    already_downloaded = set(os.listdir(DOWNLOAD_DIR))
    url_list = []

    # (2) ë“œë¼ì´ë²„ ì´ˆê¸°í™”
    def init_driver():
        chrome_opts = Options()
        chrome_opts.add_argument("--headless")
        chrome_opts.add_argument("--disable-gpu")
        chrome_opts.add_argument(f"user-agent={HEADERS['User-Agent']}")
        driver = webdriver.Chrome(service=Service(DRIVER_PATH), options=chrome_opts)
        wait = WebDriverWait(driver, 10)
        return driver, wait

    # (3) íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ
    def sanitize_filename(name, max_length=25):
        cleaned = re.sub(r'[\\/*?:"<>|]', '_', name)
        return cleaned[:max_length]

    driver, wait = init_driver()
    driver.get(LIST_URL)
    time.sleep(1)

    # â€” 1) ì˜¤ëŠ˜ìë§Œ í•„í„°ë§ â€”
    today = datetime.today().date()
    print(f"ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ì¡°íšŒ: {today}")

    # ìœ í˜• ì„¤ì •
    Select(driver.find_element(By.ID, "srchTypeAisTpCd")).select_by_value("05")
    wait.until(EC.visibility_of_element_located((By.ID, "aisTpCdData05")))
    Select(driver.find_element(By.ID, "aisTpCdData05")).select_by_value("")
    Select(driver.find_element(By.ID, "cnpCd")).select_by_value("")
    Select(driver.find_element(By.ID, "panSs")).select_by_value("")

    # ë‚ ì§œ í•„í„°
    # startDt í•„ë“œì— today ì„¤ì •
    start_input = driver.find_element(By.ID, "startDt")
    driver.execute_script(
        "arguments[0].removeAttribute('readonly'); arguments[0].value = arguments[1];",
        start_input,
        today.strftime("%Y-%m-%d")
    )

    # endDt í•„ë“œì— today ì„¤ì •
    end_input = driver.find_element(By.ID, "endDt")
    driver.execute_script(
        "arguments[0].removeAttribute('readonly'); arguments[0].value = arguments[1];",
        end_input,
        today.strftime("%Y-%m-%d")
    )

    btn = wait.until(EC.element_to_be_clickable((By.ID, "btnSah")))
    btn.click()

    # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
    wait.until(EC.element_to_be_clickable((By.ID, "btnSah"))).click()
    time.sleep(3)

    # â€” 2) ì˜¤ëŠ˜ì ê³µê³  í™•ì¸ & ì—†ìœ¼ë©´ ì¢…ë£Œ â€”
    row_links = driver.find_elements(By.CSS_SELECTOR, "a.wrtancInfoBtn")
    if not row_links:
        print("âŒ ì˜¤ëŠ˜ì ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        driver.quit()
        return url_list

    print(f"â–¶ ì˜¤ëŠ˜ì ê³µê³  ìˆ˜: {len(row_links)}ê±´")
    session = requests.Session()
    session.headers.update(HEADERS)

    # â€” 3) í•œ í˜ì´ì§€ë§Œ ìˆœíšŒí•˜ë©° ê³µê³ ë¬¸ ë‹¤ìš´ë¡œë“œ â€”
    for idx in range(len(row_links)):
        # â—ï¸ ë§¤ ë°˜ë³µë§ˆë‹¤ fresh ìš”ì†Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜µë‹ˆë‹¤
        row_links = driver.find_elements(By.CSS_SELECTOR, "a.wrtancInfoBtn")
        link = row_links[idx]
        wrtan_no = link.get_attribute("data-id1")
        print(f"\n[{idx+1}] ê³µê³  í´ë¦­: {wrtan_no}")
        link.click()
        time.sleep(2)

        # ê³µê³ ì¼
        try:
            pub_date_text = driver.find_element(By.XPATH, "//li[strong[text()='ê³µê³ ì¼']]").text
            pub_date = pub_date_text.replace("ê³µê³ ì¼", "").strip().replace(".", "")
        except:
            pub_date = today.strftime("%Y%m%d")

        # ê³µê³ ë¬¸ ë¦¬ìŠ¤íŠ¸
        try:
            dl = driver.find_element(By.CSS_SELECTOR, "dl.col_red")
            items = dl.find_elements(By.XPATH, ".//dt[text()='ê³µê³ ë¬¸']/following-sibling::dd//li")
        except:
            print("    âš ï¸ ê³µê³ ë¬¸ ì„¹ì…˜ ì—†ìŒ, ê±´ë„ˆëœë‹ˆë‹¤.")
            driver.back()
            time.sleep(1)
            continue

        print(f"    â–¶ ê³µê³ ë¬¸ íŒŒì¼ ìˆ˜: {len(items)}")
        for li in items:
            a = li.find_element(By.TAG_NAME, "a")
            filename = a.text.strip()
            name_part, ext = os.path.splitext(filename)
            if 'ê³µê³ ' not in filename or ext.lower() != '.pdf':
                continue
            short_name = sanitize_filename(name_part)
            file_id = a.get_attribute("href").split("'")[1]
            file_url = f"{DOWNLOAD_URL}?fileid={file_id}"
            safe_filename = f"{wrtan_no}_{pub_date}_{short_name}{ext}"
            save_path = os.path.join(DOWNLOAD_DIR, safe_filename)

            if safe_filename in already_downloaded:
                print(f"    â­ï¸ ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨ â†’ {safe_filename}")
            else:
                resp = session.get(file_url, headers={"Referer": driver.current_url, "User-Agent": HEADERS["User-Agent"]})
                resp.raise_for_status()
                with open(save_path, "wb") as fw:
                    fw.write(resp.content)
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ â†’ {save_path}")
                already_downloaded.add(safe_filename)

            # ìˆ˜ì • - safe_filename ì¶”ê°€ 
            url_list.append((file_url, safe_filename, {"wrtan_no": wrtan_no, "pub_date": pub_date, "filename": filename}))

        # ë’¤ë¡œê°€ê¸°
        driver.back()
        wait.until(EC.element_to_be_clickable((By.ID, "btnSah")))
        time.sleep(1)

    driver.quit()
    print("âœ… ì˜¤ëŠ˜ì ê³µê³ ë¬¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    return url_list

if __name__ == "__main__":
    collected_urls = collect_lh_file_urls()
    print(f"\nâ­ ìµœì¢… ìˆ˜ì§‘ëœ íŒŒì¼ ìˆ˜: {len(collected_urls)}ê°œ")
