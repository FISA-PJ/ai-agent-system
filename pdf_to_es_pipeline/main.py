import os
from dotenv import load_dotenv
from langchain.schema import Document
from elasticsearch import Elasticsearch
from elasticsearch import NotFoundError, TransportError
from langchain_elasticsearch import ElasticsearchStore

from processor1_pdf2md import Parser2Markdown
from processor2_chunking import HeaderSplitter, SemanticSplitter
from processor3_embedding import BgeM3Embedding

load_dotenv()
os.chdir('experiment_results_upstage/') # ì´ê±´ ì‹œí—˜ìš© (ì´ë¯¸ íŒŒì‹±ëœ HTML ë¬¸ì„œ í´ë”)
#os.chdir('../data/')

# ë³€ìˆ˜ ìƒì„±
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY") 
preprocessor = Parser2Markdown(UPSTAGE_API_KEY)

embeddings = BgeM3Embedding()
header_splitter = HeaderSplitter()
second_splitter = SemanticSplitter(embeddings)
es =  Elasticsearch('http://localhost:9200')
index_name = "test-0524-tmp"

vectorstore = ElasticsearchStore(
    index_name=index_name,
    embedding=embeddings,
    es_connection=es,
)

    
# ì´ë¯¸ íŒŒì‹±ëœ íŒŒì¼ ì½ì–´ì˜¤ëŠ” ê²½ìš°
def read_md_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()


for file_name in os.listdir('.'):
    ## file_name ì˜ˆ) 0000060830_20250508_(250414)í–‰ì •ì¤‘ì‹¬ë³µí•©ë„ì‹œ6-3M2ë¸”ë¡ì…ì£¼ìëª¨ì§‘ê³µê³ ë¬¸(ì •ì •-ì ‘ìˆ˜ê¸°ê°„ì—°ì¥).pdf
    print(f"======== ğŸš© {file_name} íŒŒì¼ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ========")
    
    ## 1. ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ (Elasticsearch ì¿¼ë¦¬)
    apt_code = file_name.split('_')[0] # file_name
    try:
        if es.indices.exists(index=index_name):
            delete_query = {
                "query": {
                    "term": {
                        "metadata.apt_code": apt_code
                    }
                }
            }
            response = es.delete_by_query(index=index_name, body=delete_query)
            deleted_count = response.get("deleted", 0)
            print(f"â–¶ INFO: ğŸ—‘ï¸ apt_code={apt_code} ê´€ë ¨ ë¬¸ì„œ {deleted_count}ê°œ ì‚­ì œ ì™„ë£Œ")
        else:
            print(f"â–¶ INFO: âš ï¸ ì¸ë±ìŠ¤ {index_name}ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    except NotFoundError as e:
        print(f"â–¶ INFO: ğŸš« ì‚­ì œ ì‹¤íŒ¨: (ë¬¸ì„œ ì—†ìŒ) {e}")

    except TransportError as e:
        print(f"â–¶ INFO: ğŸš¨ Elasticsearch ì—°ê²° ë˜ëŠ” ìš”ì²­ ì‹¤íŒ¨: {e.error}, ìƒíƒœ ì½”ë“œ: {e.status_code}")

    except Exception as e:
        print(f"â—ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸ ë°œìƒ: {e}")


    ## 2. PDFë¬¸ íŒŒì‹± ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ë³€í™˜  
    #html_contents = preprocessor.pdf_upstageparser(file_name)
    #html_contents = preprocessor.pdf_openparse(file_name)
    html_contents = read_md_file(file_name)
    markdown_texts = preprocessor.html2md_with_spans(html_contents) 

    doc = Document(
        page_content=markdown_texts,
        metadata={"source_pdf": file_name}
    )
    
    ## 3. 1ì°¨ í—¤ë” ê¸°ë°˜ ì²­í¬
    header_chunks = header_splitter.split_documents([doc])

    ## 4. 2ì°¨ ì˜ë¯¸ ê¸°ë°˜ ì²­í¬
    documents = second_splitter.split_documents(header_chunks)

    ## 5. ì¼ê´„ ì„ë² ë”© + ë²¡í„° ì €ì¥
    vectorstore.add_documents(documents)
    print(f"-Ë‹Ëâœ„â”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆ [ì™„ë£Œ] {len(documents)}ê°œ ë¬¸ì„œ Elasticsearchì— ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤. â”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆ\n\n")