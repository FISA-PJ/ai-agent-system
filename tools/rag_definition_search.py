from langchain.agents import tool
from langchain.schema import Document
from tools import es_client, embedding_model, reranker_model 

@tool
def rag_definition_search(user_message: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ê³¼ ì•„íŒŒíŠ¸ ì½”ë“œ(apt_code)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ê´€ë ¨ ê³µê³ ë¬¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f'ğŸ”[rag_definition_search] ì…ë ¥ê°’ : {user_message}')
    query_vec = embedding_model.embed_query(user_message)

    hits = es_client.search(index="test-0524-tmp", body={
        "knn": {
            "field": "vector",
            "query_vector": query_vec,
            "k": 10,
            "num_candidates": 20
        }
    })["hits"]["hits"]

    docs = [
        Document(
            page_content=hit["_source"]["text"],
            metadata=hit["_source"].get("metadata", {})
        ) for hit in hits
    ]

    reranked = reranker_model.rerank(user_message, docs, top_k=3)

    results = [f"{i+1}. {doc.page_content}" for i, (doc, score) in enumerate(reranked)]
    return "\n".join(results)